---
title: "2024-02-18"
tags:
- blog
---
So I've been successfully using Claude to avoid AI detectors. Here's the score of the latest one (it took me four minutes from modifying my crafted prompt after writing this post to pasting it into GPTZero's supposed detector):

![[Screenshot 2024-02-18 at 6.19.36 PM.png]]

![[Screenshot 2024-02-18 at 6.16.25 PM.png]]

> Most AI detectors are unable to differentiate between text that is either AI or human (eg. 50% AI probability) or text that is a combination of AI and human (ie. mixed output). The difference is made here.

Look at that and how *proud* they are of their detector that doesn't work. This was before any edits. All edits were made prior to pressing submit. In goes a chapter of text and a prompt, out it spits with "100% human" text (there's no sign that it's mixed. I tried to find that 4%, but it didn't exist. They were just covering their behind there by not giving this one a 100% human-generated rating as they usually do).

Claude is difficult to master, but, once you've actually RTFM (read the instructions), it's surprisingly powerful. I've actually had someone mark me down for ~~being white~~ not writing enough, even though everyone knows that Claude, if anything, is far too verbose in its responses.

Their deep dive even explains why they're so certain that the text is 100% human-generated:
![[Screenshot 2024-02-18 at 6.18.03 PM.png]]
---

I still prefer GPT-4-0314 for test-taking, as it seems that's what the MoE model was built for.

("that" = processing chunks of text/logic like a human)

GPT-4-0125-preview sorta works, too. Plus it's 3x cheaper, so it's definitely worth considering for high-volume apps if you're working with many users.