---
title: "2024-01-23"
tags:
- blog
---
Hot take #1:
I can recognize AI writing. It's pretty easy to pick up something that ChatGPT wrote on its own. It writes far better and far more verbosely than a human, and, more importantly, more formulaically. No matter what prompt you give it, the result will always follow some sort of formula. Humans aren't nearly as perfect, so they don't always follow a formula when writing.

Caveat: Granted, I find it much easier to detect only when the prompt was given with the default temperature values of 0.7 to 1.0 coupled with top-p sampling, rather than using something like top-k sampling to determine words.
Side note: As I understand it, temperature allows top-p to be more deterministic, while avoiding (a) top-k's pitfalls of ignoring context and including too much randomness and (b) greedy sampling's pitfalls of extreme determinism where the result is always the same.

Hot take #2:
I use LLMs, mostly OpenAI's transformer models, for the majority of my professional writing—though, not for this article (in fact, if I'd used it for this article, there would be no parentheses here, as parentheses aren't "perfect" when writing). I will continue to. I'm super slow at everything, but, whenever people see me, they assume that I'm extremely fast. Why? My parents taught me to do mental math. They taught me to sit down and learn. When I got older, I got worse. I had no one forcing me to learn, forcing me to *focus*. But I got past it.