Holy. So Microsoft’s ORCA2 is to LLMs what DeepMind’s AlphaZero was to chess. This model trains itself; no “reinforcement learning” (RLHF), so no indoctrinated bias. The only bias it will have is that which it picks up naturally from its training data.

(Side note: And now I understand why Google is so quick to push Reddit to the top of search results and promote a “diverse” internet. The machines will learn based on what they see, so, if you want to ingrain some sort of prejudice, you need that to be what they see most often. Of course, the real goal is to *exclude* prejudice, but we’ll see how well it works.)

This is the future of computing. eXplainable AI.

—

Again, this is all theoretical. According to the way, they planned to train orca, it seems that it’s learning from GPT-4. While GPT-4 has the least “bias” (couples with the superiority complex for Claude and Gemini), it’s still initially trained on human feedback. So their first principles are really still reinforcement learning. 